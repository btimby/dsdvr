import os
import sys
import logging
import uuid
import subprocess
import socket
import tempfile
import signal
import time
import multiprocessing
import select
import errno
import shutil

from os.path import join as pathjoin
from os.path import dirname, isfile

import psutil
import daemon

from django.http import FileResponse, Http404
from django.urls import reverse
from django.shortcuts import get_object_or_404
from django.db.transaction import atomic

from rest_framework import viewsets
from rest_framework import status

from api.models import Stream
from api.serializers import StreamSerializer
from main import util


LOGGER = logging.getLogger(__name__)
LOGGER.setLevel(logging.DEBUG)
LOGGER.addHandler(logging.NullHandler())

WRITER_PROCESS_NAMES = ['ffmpeg']


def find_free_port(interface='localhost'):
    '''
    Finds a free port on given interface.

    Useful if you need to spawn ffmpeg as a server.
    '''
    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
    s.bind((interface, 0))
    try:
        return s.getsockname()[1]

    finally:
        s.close()


def _find_writers(path):
    '''
    Return pids of processes writing to given path. Only considers processes
    whose name is contained within WRITER_PROCESS_NAMES. Such filtering is an
    optimization as scanning all open files for all processes takes a
    considerable amount of time.
    '''
    pids = []

    for p in psutil.process_iter(attrs=['name']):
        # As of now, the only process that should be writing our video is
        # ffmpeg.
        if p.info['name'] not in WRITER_PROCESS_NAMES:
            continue

        try:
            files = p.open_files()

        except (psutil.NoSuchProcess, psutil.AccessDenied):
            # Process may have just died...
            continue

        else:
            # See if the ffmpeg process is writing to our video.
            for file in files:
                if file.path == path and 'w' in file.mode:
                    pids.append(p.pid)

    return pids


def _alive(pids):
    '''
    Return True if any of the given pids are alive.
    '''
    return any([p for p in pids if psutil.pid_exists(p)])


def _tail(process, input, pids):
    written, where, last_data = 0, 0, time.time()

    while True:
        # See if our streams are ready for I/O...
        input_readable = where < os.fstat(input.fileno()).st_size
        output_writable = \
            select.select([], [process.stdin], [], 1.0)[1]

        if input_readable and output_writable:
            data = input.read()
            if data:
                written += len(data)
                where, last_data = input.tell(), time.time()
                process.stdin.write(data)

            elif not pids and not input_readable:
                # No writers, EOF
                break

        else:
            time.sleep(1.0)

        # If all of our writer pids have died, and we have not seen
        # data for 5s, move to next file.
        if not _alive(pids) and last_data < time.time() - 5:
            break

    LOGGER.debug('Wrote %i bytes from %s', written, input.name)


def _tails(process, paths):
    '''
    Read each path in turn and write it to the given process.

    Don't stop reading a file until no new data has arrived for 5s and no
    writing processes are detected. This allows us to stream a video from disk
    that is being generated by another process.

    Conceptually, this is like using tail -f on an apache log file, and when
    apache closes it's log, tail exits. Piping this tail-alike's output to
    another process, would cause THAT process to also die when apache closes
    it's log.

    Close the process.stdin when done. Typically this will cause the process to
    exit due to EOF.
    '''
    try:
        for path in paths:
            # Find processes currently writing to the file.
            pids = _find_writers(path)
            LOGGER.debug(
                'Found %i writers for path "%s": %s', len(pids), path,
                ",".join([str(p) for p in pids]))

            with open(path, 'rb') as input:
                _tail(process, input, pids)

        LOGGER.info('Input EOF, _tail() exiting.')
        process.stdin.close()
        process.send_signal(signal.SIGINT)
    
    finally:
        try:
            r = process.wait(5)
            LOGGER.debug('ffmpeg died with: %i', r)

        except subprocess.TimeoutExpired:
            LOGGER.debug('Terminating ffmpeg')
            process.terminate()
            process.wait()


def _daemonize(command, paths, pid_file_path):
    '''
    Fork into background so our transcoding won't die with us.
    '''
    with daemon.DaemonContext(
            detach_process=True,
            pidfile=Pidfile(pid_file_path)):

        log_file_path = pathjoin(dirname(paths[0]), 'ffmpeg.stderr')
        
        with open(log_file_path, 'ab') as log_file:
            log_file.write(b'\n%s\n\n' % (' '.join(command)).encode('utf8'))
            log_file.flush()

            process = subprocess.Popen(
                command, stdin=subprocess.PIPE, stderr=log_file, shell=False)

            _tails(process, paths)

def _tail_to_ffmpeg(paths, command):
    '''
    Spawn a command and send a number of files to it's stdin.
    '''
    LOGGER.info(
        'Piping %i files to: "%s"', len(paths), " ".join(command))

    pid_file_path = pathjoin(dirname(paths[0]), 'ffmpeg.pid')

    # daemon kills the host process, so start an intermediary...
    p_tail = multiprocessing.Process(
        target=_daemonize, args=(command, paths, pid_file_path))
    p_tail.daemon = False
    p_tail.start()

    pid, start = None, time.time()
    while time.time() - start < 2:
        if isfile(pid_file_path):
            with open(pid_file_path, 'r') as pid_file:
                pid = int(pid_file.read())
            os.remove(pid_file_path)
            break
        time.sleep(0.1)

    return pid


class Pidfile(object):
    def __init__(self, path):
        self.path = path

    def __enter__(self, *args, **kwargs):
        file = open(self.path, 'w')
        self.file = file.__enter__(*args, **kwargs)
        self.file.write(str(os.getpid()))
        self.file.flush()

    def __exit__(self, *args, **kwargs):
        self.file.__exit__(*args, **kwargs)


class CreatingStreamSerializer(StreamSerializer):
    @atomic
    def create(self, validated_data):
        obj = super().create(validated_data)

        temp = tempfile.mkdtemp(
            dir=obj.media.path, prefix='.stream-%s-' % obj.id)
        playlist = pathjoin(temp, 'stream.m3u8')
        file_names = util.get_recordings(obj.media.path)

        # TODO: we need to detect the existing format and decide whether to
        # transcode or copy.
        command = [
            'ffmpeg', '-loglevel', 'error', '-i', 'pipe:0', '-c:v', 'h264',
            '-c:a', 'copy', '-flags', '+cgop', '-g', '30', '-hls_list_size',
            '0', '-hls_time', '3', playlist,
        ]

        # The video file could be written to, use tail to follow the file.
        pid = _tail_to_ffmpeg(file_names, command)
        obj.update(pid=pid, path=temp)

        return obj

    def delete(self, pk):
        get_object_or_404(Stream, pk=pk).delete()
        return Response('', status=status.HTTP_204_NO_CONTENT)


class StreamViewSet(viewsets.ModelViewSet):
    serializer_class = CreatingStreamSerializer
    queryset = Stream.objects.all()


def playlist(request, pk):
    # TODO: we may wish to generate or modify this playlist. Although leaving
    # it alone may allow the player to rewind etc. The playlist controls the
    # options available to the user.
    stream = get_object_or_404(Stream, pk=pk, type=Stream.TYPE_HLS)
    playlist_path = pathjoin(stream.path, 'stream.m3u8')

    try:
        playlist_file = open(playlist_path, 'rb')

    except IOError as e:
        if e.errno != errno.ENOENT:
            raise
        raise Http404()

    return FileResponse(playlist_file)


def segment(request, pk, name):
    # TODO: we can use the requested segment and UserAgent to store a cursor
    # for later resuming of playback
    stream = get_object_or_404(Stream, pk=pk, type=Stream.TYPE_HLS)
    segment_path = pathjoin(stream.path, '%s.ts' % name)

    try:
        segment_file = open(segment_path, 'rb')

    except IOError as e:
        if e.errno != errno.ENOENT:
            raise
        raise Http404()

    return FileResponse(segment_file)
