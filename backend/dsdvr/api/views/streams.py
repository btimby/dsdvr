import os
import logging
import subprocess
import socket
import tempfile
import signal
import time
import multiprocessing
import select
import errno

from os.path import join as pathjoin
from os.path import dirname, isfile

import psutil
import daemon
import m3u8

from django.http import FileResponse, Http404
from django.shortcuts import get_object_or_404
from django.db.transaction import atomic
from django.utils import timezone

from constance import config

from rest_framework import viewsets
from rest_framework import status

from api.models import Stream
from api.serializers import StreamSerializer


LOGGER = logging.getLogger(__name__)
LOGGER.setLevel(logging.DEBUG)
LOGGER.addHandler(logging.NullHandler())

WRITER_PROCESS_NAMES = ('ffmpeg', 'python')


class InvalidStreamError(Exception):
    pass


def validate_stream(stream):
    # First check pid, if pid is alive
    # Then check files, if pid is alive and there are files: Valid
    # If there are files and pid is dead, then check playlist, segments and
    # run-length.
    try:
        os.kill(stream.pid, 0)

    except ProcessLookupError:
        pid_alive = False
    else:
        pid_alive = True

    try:
        playlist_path = pathjoin(stream.abs_path, 'stream.m3u8')
        if pid_alive and isfile(playlist_path):
            # The pid is alive and the playlist exists, we can be reasonably
            # sure the stream is good (being transcoded)
            return

        elif pid_alive:
            # The pid is alive, but there is not yet a playlist. If the stream
            # was modified recently, it may still be starting up.
            if (stream.modified - timezone.now()).total_seconds() >= 8:
                raise InvalidStreamError(
                    'Transcoder produced no output in 8 seconds.')
            return

        else:
            # Process is dead, it may be finished, validate that all segments
            # exist. Also accumulate their durations to compare to original
            # media duration.
            duration, playlist = 0.0, m3u8.load(playlist_path)
            for segment in playlist.segments:
                segment_path = pathjoin(stream.abs_path, segment.uri)
                if not isfile(segment_path):
                    raise InvalidStreamError(
                        'Segment not a file: %s' % segment_path)
                duration += segment.duration

            # The stream is intact, check that it's total duration is within 1%
            # of the media duration.
            ratio = duration / stream.media.duration
            if ratio < 0.99:
                raise InvalidStreamError(
                    'Stream duration: %i / %i == %i' % (
                        duration, stream.media.duration, ratio))

            # Holy shit, it might be good.
            return

    except InvalidStreamError:
        # If we found an error, delete the bad stream and raise it.
        stream.delete()
        raise


def find_free_port(interface='localhost'):
    '''
    Finds a free port on given interface.

    Useful if you need to spawn ffmpeg as a server.
    '''
    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
    s.bind((interface, 0))
    try:
        return s.getsockname()[1]

    finally:
        s.close()


def _find_writers(path):
    '''
    Return pids of processes writing to given path. Only considers processes
    whose name is contained within WRITER_PROCESS_NAMES. Such filtering is an
    optimization as scanning all open files for all processes takes a
    considerable amount of time.
    '''
    pids = []

    for p in psutil.process_iter(attrs=['name']):
        # As of now, the only process that should be writing our video is
        # ffmpeg.
        if p.info['name'] not in WRITER_PROCESS_NAMES:
            continue

        try:
            files = p.open_files()

        except (psutil.NoSuchProcess, psutil.AccessDenied):
            # Process may have just died...
            continue

        else:
            # See if the ffmpeg process is writing to our video.
            for file in files:
                if file.path == path and 'w' in file.mode:
                    pids.append(p.pid)

    return pids


def _alive(pids):
    '''
    Return True if any of the given pids are alive.
    '''
    return any([p for p in pids if psutil.pid_exists(p)])


def _tail(path, process):
    '''
    Read each path in turn and write it to the given process.

    Don't stop reading a file until no new data has arrived for 5s and no
    writing processes are detected. This allows us to stream a video from disk
    that is being generated by another process.

    Conceptually, this is like using tail -f on an apache log file, and when
    apache closes it's log, tail exits. Piping this tail-alike's output to
    another process, would cause THAT process to also die when apache closes
    it's log.

    Close the process.stdin when done. Typically this will cause the process to
    exit due to EOF.
    '''
    try:
        # Find processes currently writing to the file.
        pids = _find_writers(path)
        LOGGER.debug(
            'Found %i writers for path "%s": %s', len(pids), path,
            ",".join([str(p) for p in pids]))

        with open(path, 'rb') as input:
            written, where, last_data = 0, 0, time.time()

            while True:
                # See if our streams are ready for I/O...
                input_readable = where < os.fstat(input.fileno()).st_size
                output_writable = \
                    select.select([], [process.stdin], [], 1.0)[1]

                if input_readable and output_writable:
                    data = input.read()
                    if data:
                        written += len(data)
                        where, last_data = input.tell(), time.time()
                        process.stdin.write(data)

                    elif not pids and not input_readable:
                        # No writers, EOF
                        break

                else:
                    time.sleep(1.0)

                # If all of our writer pids have died, and we have not seen
                # data for 5s, move to next file.
                if not _alive(pids) and last_data < time.time() - 5:
                    break

            LOGGER.debug('Wrote %i bytes from %s', written, input.name)

        LOGGER.info('Input EOF, _tail() exiting.')
        process.stdin.close()
        process.send_signal(signal.SIGINT)
    
    finally:
        try:
            r = process.wait(5)
            LOGGER.debug('ffmpeg died with: %i', r)

        except subprocess.TimeoutExpired:
            LOGGER.debug('Terminating ffmpeg')
            process.terminate()
            process.wait()


def _daemonize(src, command, dst, pid_file):
    '''
    Fork into background so our transcoding won't die with us.
    '''
    with daemon.DaemonContext(
            detach_process=True,
            pidfile=pid_file):

        log_file_path = pathjoin(dirname(dst), 'ffmpeg.stderr')
        
        with open(log_file_path, 'ab') as log_file:
            log_file.write(b'\n%s\n\n' % (' '.join(command)).encode('utf8'))
            log_file.flush()

            process = subprocess.Popen(
                command, stdin=subprocess.PIPE, stderr=log_file, shell=False)

            _tail(src, process)


def _tail_to_ffmpeg(src, command, dst):
    '''
    Spawn a command and send a number of files to it's stdin.
    '''
    pid_file = Pidfile(pathjoin(dirname(dst), 'ffmpeg.pid'))

    # daemon kills the host process, so start an intermediary...
    p_tail = multiprocessing.Process(
        target=_daemonize, args=(src, command, dst, pid_file))
    p_tail.daemon = False
    p_tail.start()

    # Once daemonized, our worker will write it's pid to a file... Wait for
    # that file to appear and then retrieve the pid.
    return pid_file.poll()


class Pidfile(object):
    def __init__(self, path):
        self.path = path

    def __enter__(self, *args, **kwargs):
        file = open(self.path, 'w')
        self.file = file.__enter__(*args, **kwargs)
        self.file.write(str(os.getpid()))
        self.file.flush()

    def __exit__(self, *args, **kwargs):
        self.file.__exit__(*args, **kwargs)
        try:
            os.remove(self.path)

        except (IOError, OSError) as e:
            LOGGER.exception(e)

    def poll(self, timeout=1):
        for i in range(10 * timeout):
            if isfile(self.path):
                with open(self.path, 'r') as pid_file:
                    try:
                        return int(pid_file.read())

                    except ValueError as e:
                        # NaN? Quit and don't delete file.
                        LOGGER.exception(e)
                        break
            time.sleep(0.1)


class CreatingStreamSerializer(StreamSerializer):
    @atomic
    def create(self, validated_data):
        obj = super().create(validated_data)

        temp = tempfile.mkdtemp(
            prefix='.stream-%s-' % obj.id, dir=config.STORAGE_TEMP)
        playlist = pathjoin(temp, 'stream.m3u8')

        # TODO: we need to detect the existing format and decide whether to
        # transcode or copy.
        command = [
            'ffmpeg', '-loglevel', 'error', '-i', 'pipe:0', '-c:v', 'h264',
            '-c:a', 'copy', '-flags', '+cgop', '-g', '30', '-hls_list_size',
            '0', '-hls_time', '3', playlist,
        ]

        LOGGER.debug(
            'Piping %s to: "%s"', obj.media.abs_path, " ".join(command))

        # The video file could be written to, use tail to follow the file.
        LOGGER.info('Starting transcoding daemon')
        pid = _tail_to_ffmpeg(obj.media.abs_path, command, playlist)
        LOGGER.info('Transcoding daemon on pid: %i', pid)

        obj.update(pid=pid, path=temp)

        return obj

    def delete(self, pk):
        get_object_or_404(Stream, pk=pk).delete()
        return Response('', status=status.HTTP_204_NO_CONTENT)


class StreamViewSet(viewsets.ModelViewSet):
    serializer_class = CreatingStreamSerializer
    queryset = Stream.objects.all()


def playlist(request, pk):
    # TODO: we may wish to generate or modify this playlist. Although leaving
    # it alone may allow the player to rewind etc. The playlist controls the
    # options available to the user.
    stream = get_object_or_404(Stream, pk=pk, type=Stream.TYPE_HLS)
    playlist_path = pathjoin(stream.path, 'stream.m3u8')

    try:
        playlist_file = open(playlist_path, 'rb')

    except IOError as e:
        if e.errno != errno.ENOENT:
            raise
        raise Http404()

    return FileResponse(playlist_file)


def segment(request, pk, name):
    # TODO: we can use the requested segment and UserAgent to store a cursor
    # for later resuming of playback
    stream = get_object_or_404(Stream, pk=pk, type=Stream.TYPE_HLS)
    segment_path = pathjoin(stream.path, '%s.ts' % name)

    try:
        segment_file = open(segment_path, 'rb')

    except IOError as e:
        if e.errno != errno.ENOENT:
            raise
        raise Http404()

    return FileResponse(segment_file)
