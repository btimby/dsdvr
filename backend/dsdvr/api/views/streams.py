import os
import logging
import subprocess
import socket
import tempfile
import signal
import time
import multiprocessing
import select
import errno

from os.path import join as pathjoin
from os.path import dirname, isfile

import psutil
import daemon

from django.http import FileResponse, Http404
from django.shortcuts import get_object_or_404
from django.db.transaction import atomic

from rest_framework import viewsets
from rest_framework import status

from api.models import Stream
from api.serializers import StreamSerializer
from main import settings


LOGGER = logging.getLogger(__name__)
LOGGER.setLevel(logging.DEBUG)
LOGGER.addHandler(logging.NullHandler())

WRITER_PROCESS_NAMES = ('ffmpeg',)


def find_free_port(interface='localhost'):
    '''
    Finds a free port on given interface.

    Useful if you need to spawn ffmpeg as a server.
    '''
    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
    s.bind((interface, 0))
    try:
        return s.getsockname()[1]

    finally:
        s.close()


def _find_writers(path):
    '''
    Return pids of processes writing to given path. Only considers processes
    whose name is contained within WRITER_PROCESS_NAMES. Such filtering is an
    optimization as scanning all open files for all processes takes a
    considerable amount of time.
    '''
    pids = []

    for p in psutil.process_iter(attrs=['name']):
        # As of now, the only process that should be writing our video is
        # ffmpeg.
        if p.info['name'] not in WRITER_PROCESS_NAMES:
            continue

        try:
            files = p.open_files()

        except (psutil.NoSuchProcess, psutil.AccessDenied):
            # Process may have just died...
            continue

        else:
            # See if the ffmpeg process is writing to our video.
            for file in files:
                if file.path == path and 'w' in file.mode:
                    pids.append(p.pid)

    return pids


def _alive(pids):
    '''
    Return True if any of the given pids are alive.
    '''
    return any([p for p in pids if psutil.pid_exists(p)])


def _tail(path, process):
    '''
    Read each path in turn and write it to the given process.

    Don't stop reading a file until no new data has arrived for 5s and no
    writing processes are detected. This allows us to stream a video from disk
    that is being generated by another process.

    Conceptually, this is like using tail -f on an apache log file, and when
    apache closes it's log, tail exits. Piping this tail-alike's output to
    another process, would cause THAT process to also die when apache closes
    it's log.

    Close the process.stdin when done. Typically this will cause the process to
    exit due to EOF.
    '''
    try:
        # Find processes currently writing to the file.
        pids = _find_writers(path)
        LOGGER.debug(
            'Found %i writers for path "%s": %s', len(pids), path,
            ",".join([str(p) for p in pids]))

        with open(path, 'rb') as input:
            written, where, last_data = 0, 0, time.time()

            while True:
                # See if our streams are ready for I/O...
                input_readable = where < os.fstat(input.fileno()).st_size
                output_writable = \
                    select.select([], [process.stdin], [], 1.0)[1]

                if input_readable and output_writable:
                    data = input.read()
                    if data:
                        written += len(data)
                        where, last_data = input.tell(), time.time()
                        process.stdin.write(data)

                    elif not pids and not input_readable:
                        # No writers, EOF
                        break

                else:
                    time.sleep(1.0)

                # If all of our writer pids have died, and we have not seen
                # data for 5s, move to next file.
                if not _alive(pids) and last_data < time.time() - 5:
                    break

            LOGGER.debug('Wrote %i bytes from %s', written, input.name)

        LOGGER.info('Input EOF, _tail() exiting.')
        process.stdin.close()
        process.send_signal(signal.SIGINT)
    
    finally:
        try:
            r = process.wait(5)
            LOGGER.debug('ffmpeg died with: %i', r)

        except subprocess.TimeoutExpired:
            LOGGER.debug('Terminating ffmpeg')
            process.terminate()
            process.wait()


def _daemonize(src, command, dst, pid_file):
    '''
    Fork into background so our transcoding won't die with us.
    '''
    with daemon.DaemonContext(
            detach_process=True,
            pidfile=pid_file):

        log_file_path = pathjoin(dirname(dst), 'ffmpeg.stderr')
        
        with open(log_file_path, 'ab') as log_file:
            log_file.write(b'\n%s\n\n' % (' '.join(command)).encode('utf8'))
            log_file.flush()

            process = subprocess.Popen(
                command, stdin=subprocess.PIPE, stderr=log_file, shell=False)

            _tail(src, process)


def _tail_to_ffmpeg(src, command, dst):
    '''
    Spawn a command and send a number of files to it's stdin.
    '''
    pid_file = Pidfile(pathjoin(dirname(dst), 'ffmpeg.pid'))

    # daemon kills the host process, so start an intermediary...
    p_tail = multiprocessing.Process(
        target=_daemonize, args=(src, command, dst, pid_file))
    p_tail.daemon = False
    p_tail.start()

    # Once daemonized, our worker will write it's pid to a file... Wait for
    # that file to appear and then retrieve the pid.
    return pid_file.poll()


class Pidfile(object):
    def __init__(self, path):
        self.path = path

    def __enter__(self, *args, **kwargs):
        file = open(self.path, 'w')
        self.file = file.__enter__(*args, **kwargs)
        self.file.write(str(os.getpid()))
        self.file.flush()

    def __exit__(self, *args, **kwargs):
        self.file.__exit__(*args, **kwargs)
        try:
            os.remove(self.path)

        except (IOError, OSError) as e:
            LOGGER.exception(e)

    def poll(self, timeout=1):
        for i in range(10 * timeout):
            if isfile(self.path):
                with open(self.path, 'r') as pid_file:
                    try:
                        return int(pid_file.read())

                    except ValueError as e:
                        # NaN? Quit and don't delete file.
                        LOGGER.exception(e)
                        break
            time.sleep(0.1)


class CreatingStreamSerializer(StreamSerializer):
    @atomic
    def create(self, validated_data):
        obj = super().create(validated_data)

        temp = tempfile.mkdtemp(
            prefix='.stream-%s-' % obj.id, dir=settings.STORAGE_TEMP)
        playlist = pathjoin(temp, 'stream.m3u8')

        # TODO: we need to detect the existing format and decide whether to
        # transcode or copy.
        command = [
            'ffmpeg', '-loglevel', 'error', '-i', 'pipe:0', '-c:v', 'h264',
            '-c:a', 'copy', '-flags', '+cgop', '-g', '30', '-hls_list_size',
            '0', '-hls_time', '3', playlist,
        ]

        LOGGER.debug(
            'Piping %s to: "%s"', media.abs_path, " ".join(command))

        # The video file could be written to, use tail to follow the file.
        LOGGER.info('Starting transcoding daemon')
        pid = _tail_to_ffmpeg(media.abs_path, command, playlist)
        LOGGER.info('Transcoding daemon on pid: %i', pid)

        obj.update(pid=pid, path=temp)

        return obj

    def delete(self, pk):
        get_object_or_404(Stream, pk=pk).delete()
        return Response('', status=status.HTTP_204_NO_CONTENT)


class StreamViewSet(viewsets.ModelViewSet):
    serializer_class = CreatingStreamSerializer
    queryset = Stream.objects.all()


def playlist(request, pk):
    # TODO: we may wish to generate or modify this playlist. Although leaving
    # it alone may allow the player to rewind etc. The playlist controls the
    # options available to the user.
    stream = get_object_or_404(Stream, pk=pk, type=Stream.TYPE_HLS)
    playlist_path = pathjoin(stream.path, 'stream.m3u8')

    try:
        playlist_file = open(playlist_path, 'rb')

    except IOError as e:
        if e.errno != errno.ENOENT:
            raise
        raise Http404()

    return FileResponse(playlist_file)


def segment(request, pk, name):
    # TODO: we can use the requested segment and UserAgent to store a cursor
    # for later resuming of playback
    stream = get_object_or_404(Stream, pk=pk, type=Stream.TYPE_HLS)
    segment_path = pathjoin(stream.path, '%s.ts' % name)

    try:
        segment_file = open(segment_path, 'rb')

    except IOError as e:
        if e.errno != errno.ENOENT:
            raise
        raise Http404()

    return FileResponse(segment_file)
