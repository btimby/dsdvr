import os
import logging
import uuid
import subprocess
import socket
import tempfile
import signal
import time
import threading
import select
import errno
import shutil

from os.path import join as pathjoin

import psutil

from django.http import FileResponse, Http404
from django.urls import reverse
from django.shortcuts import get_object_or_404
from django.db.transaction import atomic

from rest_framework import viewsets
from rest_framework import status

from api.models import Stream
from api.serializers import StreamSerializer
from main import util


LOGGER = logging.getLogger(__name__)
LOGGER.setLevel(logging.DEBUG)
LOGGER.addHandler(logging.NullHandler())

WRITER_PROCESS_NAMES = ['ffmpeg']


def find_free_port(interface='localhost'):
    '''
    Finds a free port on given interface.

    Useful if you need to spawn ffmpeg as a server.
    '''
    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
    s.bind((interface, 0))
    try:
        return s.getsockname()[1]

    finally:
        s.close()


def _find_writers(path):
    '''
    Return pids of processes writing to given path. Only considers processes
    whose name is contained within WRITER_PROCESS_NAMES. Such filtering is an
    optimization as scanning all open files for all processes takes a
    considerable amount of time.
    '''
    pids = []

    for p in psutil.process_iter(attrs=['name']):
        # As of now, the only process that should be writing our video is
        # ffmpeg.
        if p.info['name'] not in WRITER_PROCESS_NAMES:
            continue

        try:
            files = p.open_files()

        except (psutil.NoSuchProcess, psutil.AccessDenied):
            # Process may have just died...
            continue

        else:
            # See if the ffmpeg process is writing to our video.
            for file in files:
                if file.path == path and 'w' in file.mode:
                    pids.append(p.pid)

    return pids


def _alive(pids):
    '''
    Return True if any of the given pids are alive.
    '''
    return any([p for p in pids if psutil.pid_exists(p)])


def _tails(process, paths):
    '''
    Read each path in turn and write it to the given process.

    Don't stop reading a file until no new data has arrived for 5s and no
    writing processes are detected. This allows us to stream a video from disk
    that is being generated by another process.

    Conceptually, this is like using tail -f on an apache log file, and when
    apache closes it's log, tail exits. Piping this tail-alike's output to
    another process, would cause THAT process to also die when apache closes
    it's log.

    Close the process.stdin when done. Typically this will cause the process to
    exit due to EOF.
    '''
    for path in paths:
        # Find processes currently writing to the file.
        pids = _find_writers(path)
        LOGGER.debug(
            'Found %i writers for path "%s": %s', len(pids), path,
            ",".join([str(p) for p in pids]))

        where, last_data = 0, time.time()
        input = open(path, 'rb')

        try:
            while True:
                # See if our streams are ready for I/O...
                input_readable = where < os.fstat(input.fileno()).st_size
                output_writable = \
                    select.select([], [process.stdin], [], 1.0)[1]

                if input_readable and output_writable:
                    data = input.read()
                    if data:
                        where, last_data = input.tell(), time.time()

                        try:
                            process.stdin.write(data)

                        except IOError as e:
                            if e.errno == errno.EPIPE:
                                # Broken pipe error indicates process died.
                                r = process.poll()
                                if r is not None:
                                    LOGGER.error(
                                        'ffmpeg BROKEN PIPE with error %i: %s',
                                        r, util.last_3_lines(process.stderr))
                            raise

                    elif not pids and not input_readable:
                        # No writers, EOF
                        break

                else:
                    time.sleep(1.0)

                # If all of our writer pids have died, and we have not seen
                # data for 15s, move to next file.
                if not _alive(pids) and last_data < time.time() - 5:
                    break

        finally:
            input.close()

    # As desired, ffmpeg dies when we do this...
    process.stdin.close()
    process.wait()
    LOGGER.info('Input EOF, _tail() exiting.')


def _tail_to_ffmpeg(paths, command):
    '''
    Spawn a command and send a number of files to it's stdin.
    '''
    LOGGER.info(
        'Piping %i files to: "%s"', len(paths), " ".join(command))

    process = subprocess.Popen(
        command, stdin=subprocess.PIPE, stderr=subprocess.PIPE,
        encoding='utf8', shell=False)

    t_tail = threading.Thread(target=_tails, args=(process, paths))
    t_tail.daemon = True
    t_tail.start()

    return process


class CreatingStreamSerializer(StreamSerializer):
    @atomic
    def create(self, validated_data):
        obj = super().create(validated_data)

        temp = tempfile.mkdtemp(
            dir=obj.media.path, prefix='.stream-%s-' % obj.id)
        playlist = pathjoin(temp, 'stream.m3u8')
        file_names = util.get_recordings(obj.media.path)

        # TODO: we need to detect the existing format and decide whether to
        # transcode or copy.
        command = [
            'ffmpeg', '-i', 'pipe:0', '-c:v', 'h264',  # '-loglevel', 'fatal'
            '-c:a', 'copy', '-flags', '+cgop', '-g', '30', '-hls_list_size',
            '0', '-hls_time', '3', playlist,
        ]

        # The video file could be written to, use tail to follow the file.
        process = _tail_to_ffmpeg(file_names, command)

        obj.update(pid=process.pid, path=temp)

        return obj

    def delete(self, pk):
        obj = get_object_or_404(Stream, pk=pk)
        # TODO: move this to model: Stream.delete()
        if obj.pid is not None:
            os.kill(obj.pid, signal.SIGINT)
        if obj.path is not None:
            shutil.rmtree(obj.path, ignore_errors=True)
        obj.delete()
        return Response('', status=status.HTTP_204_NO_CONTENT)


class StreamViewSet(viewsets.ModelViewSet):
    serializer_class = CreatingStreamSerializer
    queryset = Stream.objects.all()


def playlist(request, pk):
    # TODO: we may wish to generate or modify this playlist. Although leaving
    # it alone may allow the player to rewind etc. The playlist controls the
    # options available to the user.
    stream = get_object_or_404(Stream, pk=pk, type=Stream.TYPE_HLS)
    playlist_path = pathjoin(stream.path, 'stream.m3u8')

    try:
        playlist_file = open(playlist_path, 'rb')

    except IOError as e:
        if e.errno != errno.ENOENT:
            raise
        raise Http404()

    return FileResponse(playlist_file)


def segment(request, pk, name):
    # TODO: we can use the requested segment and UserAgent to store a cursor
    # for later resuming of playback
    stream = get_object_or_404(Stream, pk=pk, type=Stream.TYPE_HLS)
    segment_path = pathjoin(stream.path, '%s.ts' % name)

    try:
        segment_file = open(segment_path, 'rb')

    except IOError as e:
        if e.errno != errno.ENOENT:
            raise
        raise Http404()

    return FileResponse(segment_file)
